{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the notebook for designing semiconductor heterostructures based on Materials Project data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import scipy.constants as cons\n",
    "import os\n",
    "import bisect\n",
    "import re\n",
    "import itertools\n",
    "#from sklearn import svm\n",
    "#from sklearn.model_selection import cross_validate as cross_validation\n",
    "from shutil import copyfile\n",
    "import collections\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next section performs preprocessing of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Abundances.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     ENegDif\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(ENegC)\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mmin\u001b[39m(ENegC)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m CostVal,ENegDif\n\u001b[0;32m---> 14\u001b[0m MaterialAbundances\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenfromtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAbundances.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m ENegData\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mgenfromtxt(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mElectronegativity.txt\u001b[39m\u001b[38;5;124m'\u001b[39m,dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m Elements\u001b[38;5;241m=\u001b[39m[]\n",
      "File \u001b[0;32m~/miniconda3/envs/viz/lib/python3.10/site-packages/numpy/lib/npyio.py:1813\u001b[0m, in \u001b[0;36mgenfromtxt\u001b[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding, like)\u001b[0m\n\u001b[1;32m   1811\u001b[0m     fname \u001b[38;5;241m=\u001b[39m os_fspath(fname)\n\u001b[1;32m   1812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m-> 1813\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_datasource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1814\u001b[0m     fid_ctx \u001b[38;5;241m=\u001b[39m contextlib\u001b[38;5;241m.\u001b[39mclosing(fid)\n\u001b[1;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/viz/lib/python3.10/site-packages/numpy/lib/_datasource.py:193\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03mOpen `path` with `mode` and return the file object.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m \n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m ds \u001b[38;5;241m=\u001b[39m DataSource(destpath)\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/viz/lib/python3.10/site-packages/numpy/lib/_datasource.py:532\u001b[0m, in \u001b[0;36mDataSource.open\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _file_openers[ext](found, mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m    530\u001b[0m                               encoding\u001b[38;5;241m=\u001b[39mencoding, newline\u001b[38;5;241m=\u001b[39mnewline)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 532\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Abundances.txt not found."
     ]
    }
   ],
   "source": [
    "def CostFunction(CostName):\n",
    "    CostVal=0.0\n",
    "    ENegC=[]\n",
    "    for k in range(0,len(CostName),2):\n",
    "        ElementIndex=Elements.index(CostName[k])\n",
    "        CostVal+=float(CostName[k+1])/Abundances[ElementIndex]\n",
    "        \n",
    "        OrderedElementIndex=OrderedElements.index(CostName[k])\n",
    "        ENegC.append(Electronegativity[OrderedElementIndex])\n",
    "    ENegDif=max(ENegC)-min(ENegC)\n",
    "        \n",
    "    return CostVal,ENegDif\n",
    "\n",
    "MaterialAbundances=np.genfromtxt('Abundances.txt',dtype=None)\n",
    "ENegData=np.genfromtxt('Electronegativity.txt',dtype=None)\n",
    "Elements=[]\n",
    "Abundances=[]\n",
    "OrderedElements=[]\n",
    "Electronegativity=[]\n",
    "for i in range(0,len(MaterialAbundances)):\n",
    "    Elements.append(MaterialAbundances[i][0].decode(\"utf-8\"))\n",
    "    Abundances.append(float(MaterialAbundances[i][1]))\n",
    "for i in range(0,len(ENegData)):\n",
    "    OrderedElements.append(ENegData[i][0].decode(\"utf-8\"))\n",
    "    Electronegativity.append(ENegData[i][1])\n",
    "\n",
    "MaterialNames=np.genfromtxt('ChemComps.txt',dtype=None)\n",
    "filename3='ChemicalCompositions.txt'\n",
    "h=open(filename3,'w')\n",
    "h.write('#MP_Number'+'\\t'+'Formula'+'\\t'+'Cost'+'\\t'+'ENegDiff'+'\\t'+'Separated_Formula'+'\\n')\n",
    "\n",
    "IDs=[]\n",
    "Names=[]\n",
    "for i in range(0,len(MaterialNames)):\n",
    "    IDs.append(MaterialNames[i][0])\n",
    "    Names.append(MaterialNames[i][1].decode(\"utf-8\"))\n",
    "\n",
    "for i in range(0,len(Names)):\n",
    "    #print IDs[i],Names[i]\n",
    "    NameToTest=Names[i]\n",
    "    NameToTest= [ y for y in list(itertools.chain(*[re.split(r'\\\"(.*)\\\"', x) \n",
    "        for x in re.split(r'\\((.*)\\)', NameToTest)])) \n",
    "        if y != ''] #this splits at parenthases\n",
    "    ParenSeparatedName=[]\n",
    "    for j in range(0,len(NameToTest)):#This will check if first character is a number, due to parenthases\n",
    "        firstChar=NameToTest[j][0]\n",
    "        if firstChar.isdigit()==True:\n",
    "            ParenSeparatedName.extend([a for a in re.split(r'([A-Z][a-z]*\\d*)', NameToTest[j]) if a])\n",
    "        else:\n",
    "            #print NameToTest[j]\n",
    "            ParenSeparatedName.append(NameToTest[j])\n",
    "    #print ParenSeparatedName    \n",
    "    SeparatedName=[]\n",
    "    for j in range(0,len(ParenSeparatedName)):\n",
    "        TempSegment=[a for a in re.split(r'([A-Z][a-z]*)', ParenSeparatedName[j]) if a]\n",
    "        #print TempSegment\n",
    "        multiplier=1\n",
    "        if TempSegment[0].isdigit()==False:\n",
    "            if j<len(ParenSeparatedName)-1 and ParenSeparatedName[j+1].isdigit()==True:\n",
    "                multiplier=int(ParenSeparatedName[j+1])\n",
    "            #print multiplier #from parenthases\n",
    "            for k in range(0,len(TempSegment)):\n",
    "                #print TempSegment[k]\n",
    "                if TempSegment[k].isdigit()==False:\n",
    "                    if k<len(TempSegment)-1 and TempSegment[k+1].isdigit()==True:\n",
    "                        SeparatedName.append(TempSegment[k])\n",
    "                        SeparatedName.append(str(int(TempSegment[k+1])*multiplier))\n",
    "                    elif k<len(TempSegment)-1 and TempSegment[k+1].isdigit()==False:\n",
    "                        SeparatedName.append(TempSegment[k])\n",
    "                        SeparatedName.append(str(multiplier))\n",
    "                    elif k==len(TempSegment)-1 and TempSegment[k].isdigit()==False:\n",
    "                        SeparatedName.append(TempSegment[k])\n",
    "                        SeparatedName.append(str(multiplier))\n",
    "    \n",
    "    #now calculate cost\n",
    "    NewCost,ENegDiff2=CostFunction(SeparatedName)\n",
    "    \n",
    "    dataToWrite=[int(IDs[i]),Names[i],NewCost,ENegDiff2]+SeparatedName\n",
    "    for item in dataToWrite:\n",
    "        h.write(\"%s\\t\" % item)\n",
    "    h.write('\\n')\n",
    "\n",
    "h.close()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell defines metal versus semiconductor in terms of the band gap.  It allows for semiconductors which have small negative gaps within DFT.  The value provided here assumes that the gap has already been corrected.  The provided value assumes a linear gap correction from Setyawan $\\textit{et. al. }$ (DOI:10.1021/co200012w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MinSemicondGap=-0.677"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The folowing cell provides an initial filtering to remove metals.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-b0e3d091dc3f>:2: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  MaterialDataHold=np.genfromtxt('CNData.txt',dtype=None) #input bandstruct data from MP\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#import data from file\n",
    "MaterialDataHold=np.genfromtxt('CNData.txt',dtype=None) #input bandstruct data from MP\n",
    "#file to write filtered data\n",
    "filename2='CNData_Semicond.txt'\n",
    "g=open(filename2,'w')\n",
    "g.write('#MP_Number'+'\\t'+'CNL'+'\\t'+'EG'+'\\t'+'EFermi'+'\\t'+'ValenceMax'+'\\t'+'CondMin'+'\\n')\n",
    "\n",
    "for i in range(0,len(MaterialDataHold)): #here will get densities, EHull from materials project  \n",
    "    if (MaterialDataHold[i][2]>MinSemicondGap):\n",
    "        for item in MaterialDataHold[i]:\n",
    "            g.write(\"%s\\t\" % item)\n",
    "        g.write('\\n')\n",
    "            \n",
    "g.close()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell provides the settings for the first layer of filtering.  Specify the ranges of:\n",
    "\n",
    "-Density in g/cm$^3$\n",
    "\n",
    "-Energy above the convex hull in eV\n",
    "\n",
    "-Number of atoms in the unit cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "densityMin=2.0\n",
    "densityMax=100.0 #min and max densities\n",
    "\n",
    "eHullMin=0.0\n",
    "eHullMax=0.01\n",
    "\n",
    "NumAtomMin=0 #minimum number of atoms per unit cell\n",
    "NumAtomMax=45 #maximum number of atoms per unit cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell provides settings for the second filter.  Specify:\n",
    "\n",
    "-Elements to exclude\n",
    "\n",
    "-Materials to exclude by MPID\n",
    "\n",
    "-Range of allowed Pauling electronegativity differences\n",
    "\n",
    "-Range of number of allowed elements in the formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elements to exclude:\n",
    "ExcludeElems=['H','He','Ne','Ar','Kr','Xe','Rn','Li','Be','Tc','Hg','Tl','Rh','Re','Os',\n",
    "              'Ce','Pr','Nd','Pm','Sm','Eu','Gd','Tb','Dy','Ho','Er','Tm','Yb','Lu',\n",
    "              'Ac','Th','Pa','U','Np','Pu']\n",
    "#ExcludeElems=[]\n",
    "#MPIDs to exclude, as integer\n",
    "ExcludeIDs=[]#361,713,1342,2072,1266,8755,2784,2400,555214,3257,5367]\n",
    "\n",
    "ENegDiffMin=0.0 #minimum difference in electronegativity between most and least electronegative elements\n",
    "ENegDiffMax=2.5 #1.24 #maximum allowed ENeg difference 1.24 for O-H, 1.78 for HF, 0.79 for CH3NH3PbI3\n",
    "\n",
    "NumElementsMin=0 #minimum number of elements per compound\n",
    "NumElementsMax=3 #maximum number of elements allowed in material"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell applies the filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-81ebc8bc16ad>:2: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  MaterialDataHold=np.genfromtxt('CNData_Semicond.txt',dtype=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#import data from file\n",
    "MaterialDataHold=np.genfromtxt('CNData_Semicond.txt',dtype=None) \n",
    "Descriptors=np.genfromtxt('Descriptors.txt',dtype=None) #input physical data\n",
    "AllIDs=[] #all of these have same indexing\n",
    "AllNames=[]\n",
    "ENegDiffs=[]\n",
    "AllPrettyFormulas=[]\n",
    "AllCosts=[]\n",
    "with open('ChemicalCompositions.txt') as f: #lines are unequal length\n",
    "    next(f) #skip header\n",
    "    for line in f:\n",
    "        AllIDs.append(int(line.split('\\t')[0]))\n",
    "        AllPrettyFormulas.append(line.split('\\t')[1])\n",
    "        AllNames.append(line.split('\\t')[4:-1]) #names separated by element with numbers, example:['S', '1']\n",
    "        ENegDiffs.append(float(line.split('\\t')[3]))\n",
    "        AllCosts.append(float(line.split('\\t')[2]))\n",
    "\n",
    "filename3='CNData_DensityEHullNAt_CompENeg.txt'\n",
    "h=open(filename3,'w')\n",
    "h.write('#MP_Number'+'\\t'+'CNL'+'\\t'+'EG'+'\\t'+'EFermi'+'\\t'+'ValenceMax'+'\\t'+'CondMin'+'\\t'+'ENegDiff'+'\\t'+'Formula'+'\\t'+'Cost'+'\\n')\n",
    "for i in range(0,len(MaterialDataHold)):\n",
    "    #find separated name for ith compound in datalist\n",
    "    NameIndex=AllIDs.index(MaterialDataHold[i][0]) #finds where ith compound in CNL data is in chemical comp\n",
    "    SeparatedName=AllNames[NameIndex] #separated name of ith compound in CNL data\n",
    "    ENegDiff=ENegDiffs[NameIndex]\n",
    "    Formula=AllPrettyFormulas[NameIndex]\n",
    "    Cost=AllCosts[NameIndex]\n",
    "    Density=Descriptors[NameIndex][1]\n",
    "    eHull=Descriptors[NameIndex][2]\n",
    "    NAtom=Descriptors[NameIndex][9]\n",
    "    #filter by density, eHull, NAtom\n",
    "    if (    densityMin<=Density<=densityMax\n",
    "        and eHullMin<=eHull<=eHullMax\n",
    "        and NumAtomMin<=NAtom<=NumAtomMax\n",
    "        ):\n",
    "        #filter by elements\n",
    "        if (    set(SeparatedName).isdisjoint(set(ExcludeElems))==True\n",
    "            and 2*NumElementsMin<=len(SeparatedName)<=2*NumElementsMax\n",
    "            and ENegDiffMin<=ENegDiff<=ENegDiffMax\n",
    "            ): \n",
    "            if MaterialDataHold[i][0] in ExcludeIDs:\n",
    "                continue\n",
    "            else:\n",
    "                for item in list(MaterialDataHold[i])+[ENegDiff,Formula,Cost]:\n",
    "                    h.write(\"%s\\t\" % item)\n",
    "                h.write('\\n')         \n",
    "h.close()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell specifies the method of correcting the band gap.  Provided here is a two-tiered approach.  The first choice is that the user provides a datafile with lists of experimental band gap values.  The second is an analytic equation based on a best fit linear correction two fitting parameters from literature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GapCorrection(OriginalGap): #user defined function for gap correction\n",
    "    NewGap=SlopeCorrection*OriginalGap+InterceptCorrection #This is Curtarolo Correction\n",
    "    return NewGap\n",
    "\n",
    "SlopeCorrection=1.348#Curtarolo     #1.242 #Self\n",
    "InterceptCorrection=0.913#Curtarolo     #0.974#Self\n",
    "\n",
    "ExpData=np.genfromtxt('ExperimentalGaps.csv',dtype=None,delimiter=',') #experimentally known gaps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell applies the gap correction scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-198f53083f88>:1: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  CNLData=np.genfromtxt('CNData_DensityEHullNAt_CompENeg.txt',dtype=None)\n",
      "<ipython-input-9-198f53083f88>:4: UserWarning: genfromtxt: Empty input file: \"UserData.txt\"\n",
      "  UserData=np.genfromtxt('UserData.txt',dtype=None) #User provided data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "CNLData=np.genfromtxt('CNData_DensityEHullNAt_CompENeg.txt',dtype=None)\n",
    "UserData=[]\n",
    "try:\n",
    "    UserData=np.genfromtxt('UserData.txt',dtype=None) #User provided data\n",
    "except (TypeError):\n",
    "    pass\n",
    "    \n",
    "ExpIDs=[]\n",
    "ExpGaps=[]\n",
    "for i in range(0,len(ExpData)):\n",
    "    ExpIDs.append(ExpData[i][0])\n",
    "    ExpGaps.append(ExpData[i][1])\n",
    "\n",
    "CNLDataCorrected=copy.deepcopy(CNLData) #This will hold data with corrected band gap, change element by element\n",
    "for i in range(0,len(CNLDataCorrected)):\n",
    "    OldGap=CNLData[i][2]\n",
    "    #find Corrected Gap\n",
    "    \n",
    "    if CNLData[i][0] in ExpIDs:\n",
    "        CorrectGap=ExpGaps[ExpIDs.index(CNLData[i][0])]\n",
    "    else:\n",
    "        CorrectGap=GapCorrection(CNLData[i][2])\n",
    "    \n",
    "    GapShift=CorrectGap-OldGap #how much gap is corrected, will change CNL and CBM\n",
    "\n",
    "    CNLDataCorrected[i][1]+=GapShift/2\n",
    "    CNLDataCorrected[i][2]=CorrectGap\n",
    "    CNLDataCorrected[i][5]+=GapShift\n",
    "       \n",
    "CNLDataCorrectedCNL0=copy.deepcopy(CNLDataCorrected)\n",
    "for i in range(0,len(CNLDataCorrected)):\n",
    "    CNL=CNLDataCorrected[i][1]\n",
    "        #Now set CNL to 0 eV\n",
    "    CNLDataCorrectedCNL0[i][3]-=CNL+CNLDataCorrected[i][4]\n",
    "    CNLDataCorrectedCNL0[i][4]-=CNL+CNLDataCorrected[i][4]\n",
    "    CNLDataCorrectedCNL0[i][5]-=CNL+CNLDataCorrected[i][4]\n",
    "\n",
    "UserDataList=copy.deepcopy(UserData)\n",
    "for i in range(0,len(UserData)): #This will take user data, set CNL=0\n",
    "    UserDataList[i][3]-=UserData[i][1]+UserData[i][4]\n",
    "    UserDataList[i][4]-=UserData[i][1]+UserData[i][4]\n",
    "    UserDataList[i][5]-=UserData[i][1]+UserData[i][4]\n",
    "\n",
    "filename='CNData_DensityEHullNAt_CompENeg_GapCorr.txt'\n",
    "f=open(filename,'w')  \n",
    "f.write('#MP_Number'+'\\t'+'CNL'+'\\t'+'EG'+'\\t'+'EFermi'+'\\t'+'ValenceMax'+'\\t'+'CondMin'+'\\t'+'ENegDiff'+'\\t'+'Formula'+'\\t'+'Cost'+'\\n')\n",
    "f.writelines('\\t'.join(str(j) for j in i) + '\\n' for i in CNLDataCorrected)\n",
    "f.close()\n",
    "\n",
    "filename1='CNData_DensityEHullNAt_CompENeg_GapCorrCNL0.txt'\n",
    "g=open(filename1,'w')  \n",
    "g.write('#MP_Number'+'\\t'+'CNL'+'\\t'+'EG'+'\\t'+'EFermi'+'\\t'+'ValenceMax'+'\\t'+'CondMin'+'\\t'+'ENegDiff'+'\\t'+'Formula'+'\\t'+'Cost'+'\\n')\n",
    "g.writelines('\\t'.join(str(j) for j in i) + '\\n' for i in CNLDataCorrectedCNL0)\n",
    "g.writelines('\\t'.join(str(j) for j in i) + '\\n' for i in UserDataList)\n",
    "g.close()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell specifies materials to make into nanocrystals.  The format is (MPID, radius in nm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format is (mpid,radii in nm)\n",
    "QuantumDots=[(21276,5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell constructs the nanocrystals and appends to existing datafiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-4d5225591bcd>:13: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  ElectronicData=np.genfromtxt('CNData_DensityEHullNAt_CompENeg_GapCorrCNL0.txt',dtype=None) #This includes the gap correction\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-4d5225591bcd>:22: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  Comps=np.genfromtxt('ChemComps.txt',dtype=None)\n"
     ]
    }
   ],
   "source": [
    "def QDotID(mpid,rad): #new mpid based on material and radius\n",
    "    newid=10**8*mpid+rad*10**2\n",
    "    return newid\n",
    "\n",
    "def gapShift(rad,meEff,mhEff):\n",
    "    shift=h**2/(8*(rad*10**-9)**2*me)*(1/meEff+1/mhEff)*eV\n",
    "    return shift\n",
    "\n",
    "me=cons.electron_mass\n",
    "h=cons.h\n",
    "eV=6.241509126*10**18\n",
    "\n",
    "ElectronicData=np.genfromtxt('CNData_DensityEHullNAt_CompENeg_GapCorrCNL0.txt',dtype=None) #This includes the gap correction\n",
    "OpticalData=np.genfromtxt('OpticalProperties.txt',dtype=None)\n",
    "OpticIDs=[]\n",
    "for i in range(0,len(OpticalData)):\n",
    "    OpticIDs.append(OpticalData[i][0])\n",
    "ElectronicIDs=[]\n",
    "for i in range(0,len(ElectronicData)):\n",
    "    ElectronicIDs.append(ElectronicData[i][0])\n",
    "Descriptors=np.genfromtxt('Descriptors.txt',dtype=None)\n",
    "Comps=np.genfromtxt('ChemComps.txt',dtype=None)\n",
    "#Specify files to be appended\n",
    "ElectronicFile=open('CNData_DensityEHullNAt_CompENeg_GapCorrCNL0.txt','a')  \n",
    "OpticsFile=open('OpticalProperties.txt','a')\n",
    "DescriptorFile=open('Descriptors.txt','a')\n",
    "NameFile=open('ChemicalCompositions.txt','a')\n",
    "NameFile2=open('ChemComps.txt','a')\n",
    "    \n",
    "for i in range(0,len(QuantumDots)):\n",
    "    FilteredIndex=ElectronicIDs.index(QuantumDots[i][0]) #for electronic data\n",
    "    UnfilteredIndex=OpticIDs.index(QuantumDots[i][0])\n",
    "    mEl=OpticalData[UnfilteredIndex][2]\n",
    "    mHole=OpticalData[UnfilteredIndex][3]\n",
    "    \n",
    "    with open('ChemicalCompositions.txt') as CC:\n",
    "        for j, line in enumerate(CC):\n",
    "            if j==UnfilteredIndex+1:\n",
    "                NameLin=line.split()\n",
    "            elif j>UnfilteredIndex+1:\n",
    "                break\n",
    "    #print NameLin\n",
    "    for whichRad in range(1,len(QuantumDots[i])):\n",
    "        NewID=QDotID(QuantumDots[i][0], QuantumDots[i][whichRad])\n",
    "        GapShift=gapShift(QuantumDots[i][whichRad],mEl,mHole)\n",
    "        #print GapShift\n",
    "        ElectronicLine=copy.copy(ElectronicData[FilteredIndex])\n",
    "        ElectronicLine[0]=int(NewID)\n",
    "        ElectronicLine[1]+=GapShift/2 #CNL\n",
    "        ElectronicLine[2]+=GapShift #EG\n",
    "        ElectronicLine[3]+=-GapShift/2 #EF\n",
    "        ElectronicLine[4]+=-GapShift/2 #VBM rel to CNL\n",
    "        ElectronicLine[5]+=GapShift/2 #CBM rel to CNL\n",
    "        ElectronicFile.writelines([\"%s\\t\" % item  for item in ElectronicLine])\n",
    "        ElectronicFile.write('\\n')\n",
    "        #Now add line to OpticsFile\n",
    "        OpticsLine=copy.copy(OpticalData[UnfilteredIndex])\n",
    "        OpticsLine[0]=int(NewID)\n",
    "        OpticsFile.writelines([\"%s\\t\" % item  for item in OpticsLine])\n",
    "        OpticsFile.write('\\n')\n",
    "        #Now add line to Descriptor file\n",
    "        DescriptorLine=copy.copy(Descriptors[UnfilteredIndex])\n",
    "        DescriptorLine[0]=int(NewID)\n",
    "        DescriptorFile.writelines([\"%s\\t\" % item  for item in DescriptorLine])\n",
    "        DescriptorFile.write('\\n')\n",
    "        #Now add line to ChemicalCompositions file\n",
    "        NameLine=copy.copy(NameLin)\n",
    "        NameLine[0]=int(NewID)\n",
    "        NameFile.writelines([\"%s\\t\" % item  for item in NameLine])\n",
    "        NameFile.write('\\n')\n",
    "        #Add line to ChemComps file\n",
    "        CompsLine=copy.copy(Comps[UnfilteredIndex])\n",
    "        CompsLine[0]=int(NewID)\n",
    "        NameFile2.writelines([\"%s\\t\" % item  for item in CompsLine])\n",
    "        NameFile2.write('\\n')\n",
    "ElectronicFile.close()\n",
    "OpticsFile.close()\n",
    "DescriptorFile.close()\n",
    "NameFile.close()\n",
    "NameFile2.close()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell are the parameters used for constructing heterostructures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "Directory already Exists",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Directory already Exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/local/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3445: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "iterations=1 #number of iterations through main loop\n",
    "\n",
    "Lefts=[0]\n",
    "#2691 - CdSe\n",
    "#20351 - InP\n",
    "#100000000,100000001,100000002 - MAPbI3\n",
    "#2127600000500 PbS nanocrystal\n",
    "# Middles=[1000000000] #put [0] for all possible\n",
    "Middles=[2691]\n",
    "Rights=[0] \n",
    "#361 - Cu2O\n",
    "Layers=[]#['Left','Right']#['Left','Right']#['Left']#['Left','Right'] #Which layers for which to use SVM, empty for no S4VM\n",
    "AllLayers=['Left','Middle','Right'] #Leave this alone\n",
    "AllBad=[23204,21892,634859,1968,2858,2310,2156,1170,985829,602]\n",
    "LeftTrainingInitialGood=[554278,2858,5909,2133,856,20411] #ETL\n",
    "LeftTrainingInitialBad=[18856,19443,25620,715434,18748,361]+AllBad\n",
    "MiddleTrainingInitialGood=[]\n",
    "MiddleTrainingInitialBad=[]\n",
    "RightTrainingInitialGood=[18856,19443,25620,715434,18748,361] #HTL \n",
    "RightTrainingInitialBad=[554278,2858,5909,2133,856,20411]+AllBad\n",
    "SVMAppendFrac=0.1 #fraction of most common materials to add to SVM training set\n",
    "SVM_C=2.0 #SVM hinge function\n",
    "SVMIterations=1000000 #maximum number of iterations for individual SVM\n",
    "NewSVMPoints=10 #number of points to add to data set in S4VM\n",
    "PointCombinations=500 #number of combinations of new points to add to training set\n",
    "MaxS4VM=10 #Maximum number of S4VM loops in case of no convergence\n",
    "SVM_Kernel='linear'\n",
    "SlopeCorrection=1.348#Curtarolo     #1.242 #Self\n",
    "InterceptCorrection=0.913#Curtarolo     #0.974#Self\n",
    "S4VMChoice=1 #Method for choosing SVM surface,will maximize, 1->loss, 2->crossValidation, 3->cross/loss\n",
    "CrossValidationNum=5\n",
    "LeftExclude=0 #number of materials at end of data files to ignore\n",
    "MiddleExclude=0\n",
    "RightExclude=0\n",
    "\n",
    "if 'Left' in Layers and(not LeftTrainingInitialGood or not LeftTrainingInitialBad):\n",
    "    print ('Choose SVM training materials for Left component or turn off Left SVM')\n",
    "    exit()\n",
    "if 'Middle' in Layers and(not MiddleTrainingInitialGood or not MiddleTrainingInitialBad):\n",
    "    print ('Choose SVM training materials for Middle component or turn off Middle SVM')\n",
    "    exit()\n",
    "if 'Right' in Layers and(not RightTrainingInitialGood or not RightTrainingInitialBad):\n",
    "    print ('Choose SVM training materials for Right component or turn off Right SVM')\n",
    "    exit()\n",
    "\n",
    "\n",
    "#Here specify the minimum and maximum gaps allowed for each material.\n",
    "#These are used only if materials are NOT selected (ie selected materials override gap range\n",
    "LeftMinGap=0.0\n",
    "LeftMaxGap=6.0\n",
    "PhotoMinGap=0.8 #Minimum gap of photo layer\n",
    "PhotoMaxGap=6.0 #Maximum gap of photo layer\n",
    "RightMinGap=0.0\n",
    "RightMaxGap=6.0\n",
    "\n",
    "LeftRequireDirect='False'\n",
    "RequireDirect='False' #does photolayer gap need to be direct?\n",
    "RightRequireDirect='False'\n",
    "\n",
    "# topDirectory='ZnSnN2-0208/'#'Heterostructures_CdSe-1NoSVM/'#'SVMVerification/Heterostructures_Cu2O-11.6/'\n",
    "topDirectory='Heterostructures_CdSe-1NoSVM/'#'SVMVerification/Heterostructures_Cu2O-11.6/'\n",
    "if not os.path.exists(topDirectory): #make directory\n",
    "    os.makedirs(topDirectory)\n",
    "else:\n",
    "    sys.exit(\"Directory already Exists\")\n",
    "    \n",
    "\n",
    "#offsets between left and center, CBM offsets max,min, VBM offsets max,min\n",
    "\n",
    "\n",
    "LeftOffsets=[0.4,0.2,-0.2,-10.0] #LED\n",
    "RightOffsets=[10.0,0.2,-0.2,-0.4]\n",
    "#LeftOffsets=[-0.2,-0.8,-0.2,-0.8] #CH3NH3PbI3 solar cell\n",
    "#RightOffsets=[0.8,0.2,0.8,0.2]\n",
    "\n",
    "\n",
    "if LeftOffsets[0]<LeftOffsets[1] or LeftOffsets[2]<LeftOffsets[3]:\n",
    "    print('Check Left offsets')\n",
    "if RightOffsets[0]<RightOffsets[1] or RightOffsets[2]<RightOffsets[3]:\n",
    "    print('Check Right offsets')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell constructs heterostructures.  This step may take minutes to hours depending on parameter choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-056716c40a4d>:454: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  AllData=np.genfromtxt('CNData_DensityEHullNAt_CompENeg_GapCorrCNL0.txt',dtype=None) #This includes the gap correction\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-056716c40a4d>:346: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  CNLDataLeft=np.atleast_1d(np.genfromtxt(ValidMatFiles[0],dtype=None))\n",
      "<ipython-input-13-056716c40a4d>:347: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  PossibleMiddlesAll=np.atleast_1d(np.genfromtxt(ValidMatFiles[1],dtype=None))\n",
      "<ipython-input-13-056716c40a4d>:348: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  CNLDataRight=np.atleast_1d(np.genfromtxt(ValidMatFiles[2],dtype=None))\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'LeftOffsets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-056716c40a4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0;31m#Now combine approved materials into heterostructure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m     \u001b[0mstructuresFile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mConstructHeterostructures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAssembleFiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[0;31m#Count each layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-056716c40a4d>\u001b[0m in \u001b[0;36mConstructHeterostructures\u001b[0;34m(ValidMatFiles)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0mReferenceCBM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPossibleMiddlesAll\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCNLDataLeft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#first check if suitable for left\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mLeftOffsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0mCNLDataLeft\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mReferenceVBM\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0mLeftOffsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mLeftOffsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0mCNLDataLeft\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mReferenceCBM\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0mLeftOffsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m                 \u001b[0mPossibleLefts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 \u001b[0;31m#print CNLData[j][0][2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LeftOffsets' is not defined"
     ]
    }
   ],
   "source": [
    "def ChoosePhotolayers(Lefts,Middles,Rights,LeftMinGap,LeftMaxGap,PhotoMinGap,PhotoMaxGap,RightMinGap,RightMaxGap,LeftRequireDirect,RequireDirect,RightRequireDirect):\n",
    "    if ((RequireDirect=='True' and Middles==[0]) or\n",
    "        (LeftRequireDirect=='True' and Lefts==[0]) or\n",
    "        (RightRequireDirect=='True' and Rights==[0])\n",
    "        ): #require direct gap in middle and have free photolayer\n",
    "        Descripts=np.genfromtxt('Descriptors.txt',dtype=None)\n",
    "        DescIDs=[]\n",
    "        DescDir=[]\n",
    "        for i in range(0,len(Descripts)):\n",
    "            DescIDs.append(Descripts[i][0])\n",
    "            DescDir.append(Descripts[i][10])\n",
    "    \n",
    "    LeftData=[]\n",
    "    if Lefts: #choose photolayers for LEDs\n",
    "        if sorted(Lefts)!=[0]: \n",
    "            for i in range(0,len(AllData)):\n",
    "                if AllData[i][0] in Lefts:\n",
    "                    OpticIndex=OpticIDs.index(AllData[i][0])\n",
    "                    OpticInfo=[OpticalData[OpticIndex][1],OpticalData[OpticIndex][2],OpticalData[OpticIndex][3],OpticalData[OpticIndex][4],OpticalData[OpticIndex][5]]\n",
    "                    LeftData.append(list(AllData[i])+OpticInfo)\n",
    "        else:\n",
    "            for i in range(0,len(AllData)-LeftExclude):\n",
    "                if  (   LeftMinGap<=AllData[i][2]<=LeftMaxGap):\n",
    "                    if LeftRequireDirect=='True' and DescDir[DescIDs.index(AllData[i][0])]=='True': #Require direct gap\n",
    "                        OpticIndex=OpticIDs.index(AllData[i][0])\n",
    "                        OpticInfo=[OpticalData[OpticIndex][1],OpticalData[OpticIndex][2],OpticalData[OpticIndex][3],OpticalData[OpticIndex][4],OpticalData[OpticIndex][5]]\n",
    "                        LeftData.append(list(AllData[i])+OpticInfo)\n",
    "                    elif LeftRequireDirect=='False': #do not require direct gap\n",
    "                        OpticIndex=OpticIDs.index(AllData[i][0])\n",
    "                        OpticInfo=[OpticalData[OpticIndex][1],OpticalData[OpticIndex][2],OpticalData[OpticIndex][3],OpticalData[OpticIndex][4],OpticalData[OpticIndex][5]]\n",
    "                        LeftData.append(list(AllData[i])+OpticInfo)\n",
    "    \n",
    "    MiddleData=[]\n",
    "    if Middles: #choose photolayers for LEDs\n",
    "        if sorted(Middles)!=[0]: \n",
    "            for i in range(0,len(AllData)):\n",
    "                if AllData[i][0] in Middles:\n",
    "                    OpticIndex=OpticIDs.index(AllData[i][0])\n",
    "                    OpticInfo=[OpticalData[OpticIndex][1],OpticalData[OpticIndex][2],OpticalData[OpticIndex][3],OpticalData[OpticIndex][4],OpticalData[OpticIndex][5]]\n",
    "                    MiddleData.append(list(AllData[i])+OpticInfo)\n",
    "        else:\n",
    "            for i in range(0,len(AllData)-MiddleExclude):\n",
    "                if  (   PhotoMinGap<=AllData[i][2]<=PhotoMaxGap):\n",
    "                    if RequireDirect=='True' and DescDir[DescIDs.index(AllData[i][0])]=='True': #Require direct gap\n",
    "                        OpticIndex=OpticIDs.index(AllData[i][0])\n",
    "                        OpticInfo=[OpticalData[OpticIndex][1],OpticalData[OpticIndex][2],OpticalData[OpticIndex][3],OpticalData[OpticIndex][4],OpticalData[OpticIndex][5]]\n",
    "                        MiddleData.append(list(AllData[i])+OpticInfo)\n",
    "                    elif RequireDirect=='False': #do not require direct gap\n",
    "                        OpticIndex=OpticIDs.index(AllData[i][0])\n",
    "                        OpticInfo=[OpticalData[OpticIndex][1],OpticalData[OpticIndex][2],OpticalData[OpticIndex][3],OpticalData[OpticIndex][4],OpticalData[OpticIndex][5]]\n",
    "                        MiddleData.append(list(AllData[i])+OpticInfo)\n",
    "    \n",
    "    RightData=[]\n",
    "    if Rights: #choose photolayers for LEDs\n",
    "        if sorted(Rights)!=[0]: \n",
    "            for i in range(0,len(AllData)):\n",
    "                if AllData[i][0] in Rights:\n",
    "                    OpticIndex=OpticIDs.index(AllData[i][0])\n",
    "                    OpticInfo=[OpticalData[OpticIndex][1],OpticalData[OpticIndex][2],OpticalData[OpticIndex][3],OpticalData[OpticIndex][4],OpticalData[OpticIndex][5]]\n",
    "                    RightData.append(list(AllData[i])+OpticInfo)\n",
    "        else:\n",
    "            for i in range(0,len(AllData)-RightExclude):\n",
    "                if  (   RightMinGap<=AllData[i][2]<=RightMaxGap):\n",
    "                    if RightRequireDirect=='True' and DescDir[DescIDs.index(AllData[i][0])]=='True': #Require direct gap\n",
    "                        OpticIndex=OpticIDs.index(AllData[i][0])\n",
    "                        OpticInfo=[OpticalData[OpticIndex][1],OpticalData[OpticIndex][2],OpticalData[OpticIndex][3],OpticalData[OpticIndex][4],OpticalData[OpticIndex][5]]\n",
    "                        RightData.append(list(AllData[i])+OpticInfo)\n",
    "                    elif RightRequireDirect=='False': #do not require direct gap\n",
    "                        OpticIndex=OpticIDs.index(AllData[i][0])\n",
    "                        OpticInfo=[OpticalData[OpticIndex][1],OpticalData[OpticIndex][2],OpticalData[OpticIndex][3],OpticalData[OpticIndex][4],OpticalData[OpticIndex][5]]\n",
    "                        RightData.append(list(AllData[i])+OpticInfo)\n",
    "    \n",
    "    \n",
    "    #if MiddleData: #checks if any LEDs desired\n",
    "    filename=topDirectory+'HeterostructureLeft.txt'\n",
    "    f=open(filename,'w')  \n",
    "    f.write('#MP_Number'+'\\t'+'CNL'+'\\t'+'EG'+'\\t'+'EFermi'+'\\t'+'ValenceMax'+'\\t'+'CondMin'+'\\t'+'ENegDiff'+'\\t'+'Formula'+'\\t'+'Cost'+'\\t'+'Eps10'+'\\t'+'MeffEl'+'\\t'+'MeffHole'+'\\t'+'Exciton'+'\\t'+'JDOSEdge'+'\\n')\n",
    "    f.writelines('\\t'.join(str(j) for j in i) + '\\n' for i in LeftData)\n",
    "    f.close()\n",
    "    if not LeftData:\n",
    "        print('No Valid Left Layers Found')\n",
    "    filename=topDirectory+'HeterostructureMiddle.txt'\n",
    "    f=open(filename,'w')  \n",
    "    f.write('#MP_Number'+'\\t'+'CNL'+'\\t'+'EG'+'\\t'+'EFermi'+'\\t'+'ValenceMax'+'\\t'+'CondMin'+'\\t'+'ENegDiff'+'\\t'+'Formula'+'\\t'+'Cost'+'\\t'+'Eps10'+'\\t'+'MeffEl'+'\\t'+'MeffHole'+'\\t'+'Exciton'+'\\t'+'JDOSEdge'+'\\n')\n",
    "    f.writelines('\\t'.join(str(j) for j in i) + '\\n' for i in MiddleData)\n",
    "    f.close()\n",
    "    if not MiddleData:\n",
    "        print('No Valid Photo Layers Found')\n",
    "    filename=topDirectory+'HeterostructureRight.txt'\n",
    "    f=open(filename,'w')  \n",
    "    f.write('#MP_Number'+'\\t'+'CNL'+'\\t'+'EG'+'\\t'+'EFermi'+'\\t'+'ValenceMax'+'\\t'+'CondMin'+'\\t'+'ENegDiff'+'\\t'+'Formula'+'\\t'+'Cost'+'\\t'+'Eps10'+'\\t'+'MeffEl'+'\\t'+'MeffHole'+'\\t'+'Exciton'+'\\t'+'JDOSEdge'+'\\n')\n",
    "    f.writelines('\\t'.join(str(j) for j in i) + '\\n' for i in RightData)\n",
    "    f.close()\n",
    "    if not RightData:\n",
    "        print('No Valid Right Layers Found')\n",
    "    return\n",
    "\n",
    "\n",
    "def HingeLoss(BoundParams,Intercept,Descriptors,Classes): #Hinge loss function for finding best choice of SVM\n",
    "    values=[]\n",
    "    for qq in range(0,len(Classes)):\n",
    "        val=1-Classes[qq]*(np.dot(BoundParams,Descriptors[qq])+Intercept)\n",
    "        if val>0:\n",
    "            values.append(val)\n",
    "        else:\n",
    "            values.append(0)\n",
    "    loss=np.mean(values)+SVM_C*np.dot(BoundParams,BoundParams)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "def SVMMaterial(iteration,LayerToStudy):\n",
    "    goodLayer=np.atleast_1d(np.genfromtxt(directory+'SVMTraining'+'Iteration'+str(iteration)+'Good'+LayerToStudy+'.txt'))\n",
    "    badLayer=np.atleast_1d(np.genfromtxt(directory+'SVMTraining'+'Iteration'+str(iteration)+'Bad'+LayerToStudy+'.txt'))\n",
    "    \n",
    "    ElectronicData=AllData\n",
    "    FullElectronicData=np.genfromtxt('CNData.txt',dtype=None) #will be used for training set only, same indexing as Descriptors\n",
    "    Descriptors=np.genfromtxt('Descriptors.txt',dtype=None)\n",
    "    ENegDiffs=[]\n",
    "    with open('ChemicalCompositions.txt') as f: #lines are unequal length\n",
    "        next(f) #skip header\n",
    "        for line in f:\n",
    "            ENegDiffs.append(float(line.split('\\t')[3]))\n",
    "    #IDList=[]\n",
    "    #for i in range(0,len(ElectronicData)):\n",
    "    #    IDList.append(Descriptors[i][0])\n",
    "    IDList=OpticIDs\n",
    "    ElectronicIDList=ElectronicIDs\n",
    "    \n",
    "    #Here assemble matrix of descriptors\n",
    "    LayersData=np.genfromtxt(topDirectory+'Heterostructure'+LayerToStudy+'.txt',dtype=None)\n",
    "    numMats=len(LayersData)\n",
    "    MaterialDescriptorMatrix=[[]]*numMats\n",
    "    FilteredIDs=[]\n",
    "    for i in range(0,numMats): #This sets up matrix with all post filtered materials\n",
    "        #find location of valid material in unfiltered lists\n",
    "        materialIndex=IDList.index(LayersData[i][0]) #index in unfiltered list\n",
    "        electronicIndex=ElectronicIDList.index(LayersData[i][0])\n",
    "        FilteredIDs.append(LayersData[i][0]) #ids of materials in allowed list\n",
    "        ECNL=ElectronicData[electronicIndex][1]\n",
    "        EG=ElectronicData[electronicIndex][2]\n",
    "        Eps10=OpticalData[materialIndex][1]\n",
    "        eMass=OpticalData[materialIndex][2]\n",
    "        hMass=OpticalData[materialIndex][3]\n",
    "        excitonBinding=OpticalData[materialIndex][4]\n",
    "        EdgeJDOS=OpticalData[materialIndex][5]\n",
    "        ENegDiff=ENegDiffs[materialIndex]\n",
    "        if Descriptors[materialIndex][10]=='True':\n",
    "            direct=1.0 #direct band gap\n",
    "        else:\n",
    "            direct=-1.0 #inderect band gap\n",
    "        \n",
    "        if LayerToStudy!='Middle': #Transport Layer\n",
    "            MaterialDescriptors=[ECNL/EG, EG, Eps10, eMass, hMass,EdgeJDOS,ENegDiff]\n",
    "        else: #Photolayer\n",
    "            MaterialDescriptors=[ECNL/EG, EG, Eps10,excitonBinding,EdgeJDOS,ENegDiff]\n",
    "        MaterialDescriptorMatrix[i]=MaterialDescriptors\n",
    "    #Set up initial training set and SVM\n",
    "    InitialTrainingDesc=[[]]*(len(goodLayer)+len(badLayer))\n",
    "    InitialTrainingClasses=[1]*len(goodLayer)+[-1]*len(badLayer)\n",
    "    for i in range(0,len(goodLayer)): #This will use unfiltered material list\n",
    "        layerIndex=IDList.index(int(goodLayer[i])) #location in unfiltered\n",
    "        elecIndex=layerIndex#ElectronicIDList.index(int(goodLayer[i]))\n",
    "        ECNL=FullElectronicData[elecIndex][1]+(FullElectronicData[elecIndex][2]*(SlopeCorrection-1)+InterceptCorrection)/2\n",
    "        EG=FullElectronicData[elecIndex][2]*SlopeCorrection+InterceptCorrection\n",
    "        Eps10=OpticalData[layerIndex][1]\n",
    "        eMass=OpticalData[layerIndex][2]\n",
    "        hMass=OpticalData[layerIndex][3]\n",
    "        excitonBinding=OpticalData[layerIndex][4]\n",
    "        EdgeJDOS=OpticalData[layerIndex][5]\n",
    "        ENegDiff=ENegDiffs[layerIndex]\n",
    "        if Descriptors[layerIndex][10]=='True':\n",
    "            direct=1.0 #direct band gap\n",
    "        else:\n",
    "            direct=-1.0 #inderect band gap\n",
    "        \n",
    "        if LayerToStudy!='Middle': #Transport Layer\n",
    "            MaterialDescriptors=[ECNL/EG, EG, Eps10, eMass, hMass,EdgeJDOS,ENegDiff]\n",
    "        else: #Photolayer\n",
    "            MaterialDescriptors=[ECNL/EG, EG, Eps10,excitonBinding,EdgeJDOS,ENegDiff]\n",
    "        InitialTrainingDesc[i]=MaterialDescriptors\n",
    "    for i in range(0,len(badLayer)): #This will use unfiltered material list\n",
    "        layerIndex=IDList.index(int(badLayer[i])) #location in unfiltered\n",
    "        elecIndex=layerIndex#ElectronicIDList.index(int(badLayer[i]))\n",
    "        ECNL=FullElectronicData[elecIndex][1]+(FullElectronicData[elecIndex][2]*(SlopeCorrection-1)+InterceptCorrection)/2\n",
    "        EG=FullElectronicData[elecIndex][2]*SlopeCorrection+InterceptCorrection\n",
    "        Eps10=OpticalData[layerIndex][1]\n",
    "        eMass=OpticalData[layerIndex][2]\n",
    "        hMass=OpticalData[layerIndex][3]\n",
    "        excitonBinding=OpticalData[layerIndex][4]\n",
    "        EdgeJDOS=OpticalData[layerIndex][5]\n",
    "        ENegDiff=ENegDiffs[layerIndex]\n",
    "        if Descriptors[layerIndex][10]=='True':\n",
    "            direct=1.0 #direct band gap\n",
    "        else:\n",
    "            direct=-1.0 #inderect band gap\n",
    "        \n",
    "        if LayerToStudy!='Middle': #Transport Layer\n",
    "            MaterialDescriptors=[ECNL/EG, EG, Eps10, eMass, hMass,EdgeJDOS,ENegDiff]\n",
    "        else: #Photolayer\n",
    "            MaterialDescriptors=[ECNL/EG, EG, Eps10,excitonBinding,EdgeJDOS,ENegDiff]\n",
    "        InitialTrainingDesc[i+len(goodLayer)]=MaterialDescriptors\n",
    "    #Now get initial SVM attempt\n",
    "    clfInitial = svm.SVC(kernel=SVM_Kernel,C=SVM_C,max_iter=SVMIterations)\n",
    "    clfInitial.fit(InitialTrainingDesc,InitialTrainingClasses)\n",
    "    #print np.array(Classification)\n",
    "    scoresInitial = cross_validation.cross_val_score(clfInitial, InitialTrainingDesc, np.array(InitialTrainingClasses), cv=CrossValidationNum)    #print clf.support_vectors_\n",
    "    print(clfInitial.score(InitialTrainingDesc,InitialTrainingClasses))\n",
    "    print(scoresInitial)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scoresInitial.mean(), scoresInitial.std() * 2)) \n",
    "    \n",
    "    #Check if S4VM is desired then run\n",
    "    if NewSVMPoints>0 and PointCombinations>0:\n",
    "        #Initialize for loop over randomly chosen extra training points\n",
    "        ExtraPoints=[[]]*PointCombinations #combinations of extra materials\n",
    "        SVMOptimizing=[[]]*PointCombinations #Optimization function for each SVM fit\n",
    "        \n",
    "        IDsToChoose=[x for x in FilteredIDs if x not in goodLayer and x not in badLayer] #avoid choosing mateial already in training set\n",
    "        for i in range(0,PointCombinations): #Here generate all combinations of extra training points to be used\n",
    "            ExtraPoints[i]=random.sample(IDsToChoose,NewSVMPoints)\n",
    "        #file for writing optimization data\n",
    "        filenameOpt=directory+'Heterostructure'+LayerToStudy+'SVMOptimization.txt'\n",
    "        fOpt=open(filenameOpt,'w')\n",
    "        fOpt.write('#Trial Points'+'\\t'+'Score'+'\\t'+'-HingeLoss'+'\\t'+'CrossValidation'+'\\n')\n",
    "    \n",
    "        #begin main S4VM loop\n",
    "        for i in range(0,PointCombinations):\n",
    "            #print i\n",
    "            ThisCombination=ExtraPoints[i] #choose the extra points to use\n",
    "            ExtraPointsDescs=[[]]*NewSVMPoints #holds descriptors for new points\n",
    "            for j in range(0,NewSVMPoints): #construct descriptor lists for extra points\n",
    "                ExtraLoc=FilteredIDs.index(ThisCombination[j])\n",
    "                ExtraPointsDescs[j]=MaterialDescriptorMatrix[ExtraLoc]\n",
    "            #Now find categories with initial SVM    \n",
    "            predictExtraInitial=list(clfInitial.predict(ExtraPointsDescs))\n",
    "            #predictExtraInitial=list(np.random.choice([-1,1],NewSVMPoints)) #random assignment for testing, convergence issues\n",
    "            #Now extend Matrix for descriptors and classification\n",
    "            ExtendedTrainingDesc=InitialTrainingDesc+ExtraPointsDescs\n",
    "            ExtendedTrainingClasses=InitialTrainingClasses+predictExtraInitial\n",
    "            OldClasses=copy.copy(ExtendedTrainingClasses) #This will be updated each loop\n",
    "            NewClasses=copy.copy(InitialTrainingClasses)+[0]*len(predictExtraInitial)\n",
    "            #print OldClasses\n",
    "            for S4VMLoops in range(0,MaxS4VM):\n",
    "                #refit SVM using OldClasses\n",
    "                clfLoop = svm.SVC(kernel=SVM_Kernel,C=SVM_C,max_iter=SVMIterations)\n",
    "                clfLoop.fit(ExtendedTrainingDesc,OldClasses) #This fits SVM\n",
    "                #print np.mean(cross_validation.cross_val_score(clfLoop, ExtendedTrainingDesc, np.array(OldClasses), cv=CrossValidationNum))\n",
    "                #Now recategorize each extra point\n",
    "                for j in range(0,NewSVMPoints):\n",
    "                    NewClasses[j+len(InitialTrainingClasses)]=clfLoop.predict(ExtendedTrainingDesc[j+len(InitialTrainingClasses)])[0]\n",
    "                #print NewClasses\n",
    "                if np.allclose(OldClasses,NewClasses)==True: #no reassignment of classes\n",
    "                    break\n",
    "                else:\n",
    "                    OldClasses=copy.copy(NewClasses)\n",
    "            #print NewClasses\n",
    "            #Now have to evaluate fitness function for converged SVM surface\n",
    "            loss=float(HingeLoss(list(clfLoop.coef_[0]),clfLoop.intercept_,ExtendedTrainingDesc,NewClasses))\n",
    "            cvPoint=cross_validation.cross_val_score(clfLoop, ExtendedTrainingDesc, np.array(NewClasses), cv=CrossValidationNum).mean()\n",
    "            score=clfLoop.score(ExtendedTrainingDesc,NewClasses)\n",
    "            Optimize=ThisCombination+[score,-loss,cvPoint,cvPoint/loss] #maximize (-loss or cv or cv/loss)\n",
    "            SVMOptimizing[i]=Optimize\n",
    "            #print Optimize\n",
    "        #Write Optimization Matrix to file\n",
    "        fOpt.writelines('\\t'.join(str(j) for j in i) + '\\n' for i in SVMOptimizing)\n",
    "        fOpt.close()\n",
    "        #Choose best SVM fit\n",
    "        OptimizerValue=max(l[NewSVMPoints+S4VMChoice] for l in SVMOptimizing)\n",
    "        #print OptimizerValue\n",
    "        #for qqq in SVMOptimizing:\n",
    "        #    print qqq\n",
    "        BestSVMNum=int(np.where(np.isclose(SVMOptimizing,OptimizerValue,10**-8))[0]) #Combination of extra point leading to best SVM fit\n",
    "        #print BestSVMNum\n",
    "        #Now reevaluate to find best SVM surface\n",
    "        ThisCombination=ExtraPoints[BestSVMNum] #choose the extra points to use\n",
    "        ExtraPointsDescs=[[]]*NewSVMPoints #holds descriptors for new points\n",
    "        for j in range(0,NewSVMPoints): #construct descriptor lists for extra points\n",
    "            ExtraLoc=FilteredIDs.index(ThisCombination[j])\n",
    "            ExtraPointsDescs[j]=MaterialDescriptorMatrix[ExtraLoc]\n",
    "        #Now find categories with initial SVM    \n",
    "        predictExtraInitial=list(clfInitial.predict(ExtraPointsDescs))\n",
    "        #predictExtraInitial=list(np.random.choice([-1,1],NewSVMPoints)) #random assignment for testing\n",
    "        #Now extend Matrix for descriptors and classification\n",
    "        ExtendedTrainingDesc=InitialTrainingDesc+ExtraPointsDescs\n",
    "        ExtendedTrainingClasses=InitialTrainingClasses+predictExtraInitial\n",
    "        OldClasses=copy.copy(ExtendedTrainingClasses) #This will be updated each loop\n",
    "        NewClasses=copy.copy(InitialTrainingClasses)+[0]*len(predictExtraInitial)\n",
    "        #print OldClasses\n",
    "        for S4VMLoops in range(0,MaxS4VM):\n",
    "            #refit SVM using OldClasses\n",
    "            clfInitial = svm.SVC(kernel=SVM_Kernel,C=SVM_C,max_iter=SVMIterations)\n",
    "            clfInitial.fit(ExtendedTrainingDesc,OldClasses) #This fits SVM\n",
    "            #print np.mean(cross_validation.cross_val_score(clfLoop, ExtendedTrainingDesc, np.array(OldClasses), cv=CrossValidationNum))\n",
    "            #Now recategorize each extra point\n",
    "            for j in range(0,NewSVMPoints):\n",
    "                NewClasses[j+len(InitialTrainingClasses)]=clfInitial.predict(ExtendedTrainingDesc[j+len(InitialTrainingClasses)])[0]\n",
    "            #print NewClasses\n",
    "            if np.allclose(OldClasses,NewClasses)==True: #no reassignment of classes\n",
    "                break\n",
    "            else:\n",
    "                OldClasses=copy.copy(NewClasses)\n",
    "        #print NewClasses\n",
    "        scoresFinal = cross_validation.cross_val_score(clfInitial, ExtendedTrainingDesc, np.array(NewClasses), cv=CrossValidationNum)    #print clf.support_vectors_\n",
    "        print(clfInitial.score(ExtendedTrainingDesc,NewClasses))\n",
    "        print(scoresFinal)\n",
    "        #print clfInitial.coef_\n",
    "        print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scoresFinal.mean(), scoresFinal.std() * 2)) \n",
    "    \n",
    "    #Finished with either SVM or S4VM   \n",
    "    filename=directory+'Heterostructure'+LayerToStudy+'SVM.txt'\n",
    "    f=open(filename,'w')\n",
    "    f.write('#MP_Number'+'\\t'+'CNL'+'\\t'+'EG'+'\\t'+'EFermi'+'\\t'+'ValenceMax'+'\\t'+'CondMin'+'\\t'+'ENegDiff'+'\\t'+'Formula'+'\\t'+'Cost'+'Good?'+'\\n')\n",
    "    for i in range(0,len(np.atleast_1d(LayersData))):\n",
    "        materialID=np.atleast_1d(LayersData)[i][0]\n",
    "        materialIndex=IDList.index(materialID)\n",
    "        electronicIndex=ElectronicIDList.index(materialID)\n",
    "        ECNL=ElectronicData[electronicIndex][1]\n",
    "        EG=ElectronicData[electronicIndex][2]\n",
    "        Eps10=OpticalData[materialIndex][1]\n",
    "        eMass=OpticalData[materialIndex][2]\n",
    "        hMass=OpticalData[materialIndex][3]\n",
    "        excitonBinding=OpticalData[materialIndex][4]\n",
    "        EdgeJDOS=OpticalData[materialIndex][5]\n",
    "        ENegDiff=ENegDiffs[materialIndex]\n",
    "        if Descriptors[materialIndex][10]=='True':\n",
    "            direct=1.0 #direct band gap\n",
    "        else:\n",
    "            direct=-1.0 #inderect band gap\n",
    "        if LayerToStudy!='Middle':\n",
    "            MaterialDescriptorsCheck=[ECNL/EG, EG, Eps10, eMass, hMass,EdgeJDOS,ENegDiff]\n",
    "        else:\n",
    "            MaterialDescriptorsCheck=[ECNL/EG, EG, Eps10,excitonBinding,EdgeJDOS,ENegDiff]\n",
    "        \n",
    "        group=clfInitial.predict(MaterialDescriptorsCheck)\n",
    "        DataToWrite=list(np.atleast_1d(LayersData)[i])\n",
    "        if group==1 or materialID in goodLayer:\n",
    "            for j in DataToWrite:\n",
    "                f.write(str(j)+'\\t')\n",
    "            f.write('\\n')\n",
    "    f.close()    \n",
    "      \n",
    "    return directory+'Heterostructure'+LayerToStudy+'SVM.txt' #file name with SVM approved materials\n",
    "\n",
    "\n",
    "def ConstructHeterostructures(ValidMatFiles):\n",
    "    CNLDataLeft=np.atleast_1d(np.genfromtxt(ValidMatFiles[0],dtype=None))\n",
    "    PossibleMiddlesAll=np.atleast_1d(np.genfromtxt(ValidMatFiles[1],dtype=None))\n",
    "    CNLDataRight=np.atleast_1d(np.genfromtxt(ValidMatFiles[2],dtype=None))\n",
    "    \n",
    "    filename0=directory+'AllPossibleHeterostructures_AllFilters_LinCorr.txt'\n",
    "    f0=open(filename0,'w')\n",
    "    f0.write('#LMPID'+'\\t'+'CMPID'+'\\t'+'RMPID'+'\\t'+'LName'+'\\t'+'CName'+'\\t'+'RName'+'\\t'+'LGap'+'\\t'+'CGap'+'\\t'+'RGap'+'\\t'+'EDiff1'+'\\t'+'EDiff2'+'\\t'+'EDiff3'+'\\t'+'EDiff4'+'\\t'+'CVBM'+'\\t'+'Cost'+'\\n')\n",
    "    \n",
    "    for i in range(len(PossibleMiddlesAll)):    \n",
    "        PossibleLefts=[]\n",
    "        PossibleRights=[]\n",
    "        ReferenceVBM=PossibleMiddlesAll[i][4]\n",
    "        ReferenceCBM=PossibleMiddlesAll[i][5]\n",
    "        for j in range(len(CNLDataLeft)): #first check if suitable for left\n",
    "            if LeftOffsets[3]<=CNLDataLeft[j][4]-ReferenceVBM<=LeftOffsets[2] and LeftOffsets[1]<=CNLDataLeft[j][5]-ReferenceCBM<=LeftOffsets[0]:\n",
    "                PossibleLefts.append(j)\n",
    "                #print CNLData[j][0][2]\n",
    "        for j in range(len(CNLDataRight)):\n",
    "            #now to the right\n",
    "            if RightOffsets[3]<=CNLDataRight[j][4]-ReferenceVBM<=RightOffsets[2] and RightOffsets[1]<=CNLDataRight[j][5]-ReferenceCBM<=RightOffsets[0]:\n",
    "                PossibleRights.append(j)\n",
    "                #print CNLData[j][0][2]\n",
    "        structures=list(itertools.product(PossibleLefts,[PossibleMiddlesAll[i][0]],PossibleRights)) #All possible structures\n",
    "        #now get data to write to file\n",
    "        CName=PossibleMiddlesAll[i][7].decode('utf-8')\n",
    "        CGap=PossibleMiddlesAll[i][2]\n",
    "        CMPID=PossibleMiddlesAll[i][0]\n",
    "        CCost=PossibleMiddlesAll[i][8]\n",
    "        if len(structures)>0:\n",
    "            #filename=directory+'/PossibleHeterostructuresCurtaroloCorrectedCNL0_AllFilters_'+CName+'.txt'\n",
    "            #f=open(filename,'w')\n",
    "            #f.write('#LMPID'+'\\t'+'CMPID'+'\\t'+'RMPID'+'\\t'+'LName'+'\\t'+'CName'+'\\t'+'RName'+'\\t'+'LGap'+'\\t'+'CGap'+'\\t'+'RGap'+'\\t'+'EDiff1'+'\\t'+'EDiff2'+'\\t'+'EDiff3'+'\\t'+'EDiff4'+'\\t'+'CVBM'+'\\t'+'Cost'+'\\n') \n",
    "            for j in range(0,len(structures)):\n",
    "                LMPID=CNLDataLeft[structures[j][0]][0]\n",
    "                RMPID=CNLDataRight[structures[j][2]][0]\n",
    "                LName=CNLDataLeft[structures[j][0]][7].decode('utf-8')\n",
    "                RName=CNLDataRight[structures[j][2]][7].decode('utf-8')\n",
    "                LGap=CNLDataLeft[structures[j][0]][2]\n",
    "                RGap=CNLDataRight[structures[j][2]][2]\n",
    "                EDiff1=CNLDataLeft[structures[j][0]][5]-ReferenceCBM\n",
    "                EDiff2=CNLDataLeft[structures[j][0]][4]-ReferenceVBM\n",
    "                EDiff3=CNLDataRight[structures[j][2]][5]-ReferenceCBM\n",
    "                EDiff4=CNLDataRight[structures[j][2]][4]-ReferenceVBM\n",
    "                Cost=CNLDataLeft[structures[j][0]][8]+CNLDataRight[structures[j][2]][8]+CCost\n",
    "                #f.write(str(int(LMPID))+'\\t'+str(int(CMPID))+'\\t'+str(int(RMPID))+'\\t'+LName+'\\t'+CName+'\\t'+RName+'\\t'+str(LGap)+'\\t'+str(CGap)+'\\t'+str(RGap)+'\\t'+str(EDiff1)+'\\t'+str(EDiff2)+'\\t'+str(EDiff3)+'\\t'+str(EDiff4)+'\\t'+str(ReferenceVBM)+'\\t'+str(Cost)+'\\n')\n",
    "                f0.write(str(int(LMPID))+'\\t'+str(int(CMPID))+'\\t'+str(int(RMPID))+'\\t'+LName+'\\t'+CName+'\\t'+RName+'\\t'+str(LGap)+'\\t'+str(CGap)+'\\t'+str(RGap)+'\\t'+str(EDiff1)+'\\t'+str(EDiff2)+'\\t'+str(EDiff3)+'\\t'+str(EDiff4)+'\\t'+str(ReferenceVBM)+'\\t'+str(Cost)+'\\n')\n",
    "            #f.close()\n",
    "    f0.close()\n",
    "    \n",
    "    return filename0\n",
    "\n",
    "\n",
    "def CountStructures(StructFile):\n",
    "    HeterostructureData=np.genfromtxt(StructFile,dtype=None)\n",
    "    print('Number of Structures = ' + str(len(HeterostructureData)))\n",
    "    Compositions=np.genfromtxt('ChemComps.txt',dtype=None)\n",
    "    CompIDs=[]\n",
    "    for i in range(0,len(Compositions)):\n",
    "        CompIDs.append(Compositions[i][0])\n",
    "\n",
    "    LeftIDs=[]\n",
    "    MiddleIDs=[]\n",
    "    RightIDs=[]\n",
    "    for i in range(0,len(HeterostructureData)):\n",
    "        LeftIDs.append(HeterostructureData[i][0])\n",
    "        MiddleIDs.append(HeterostructureData[i][1])\n",
    "        RightIDs.append(HeterostructureData[i][2])\n",
    "    \n",
    "    LeftCount=collections.Counter(LeftIDs)\n",
    "    LeftNums=sorted(list(set(LeftIDs)))\n",
    "    \n",
    "    MidCount=collections.Counter(MiddleIDs)\n",
    "    MidNums=sorted(list(set(MiddleIDs)))\n",
    "    \n",
    "    RightCount=collections.Counter(RightIDs)\n",
    "    RightNums=sorted(list(set(RightIDs)))\n",
    "    \n",
    "    filename1=directory+'11LeftFrequencies.txt'\n",
    "    filename2=directory+'11MiddleFrequencies.txt'\n",
    "    filename3=directory+'11RightFrequencies.txt'\n",
    "    fl=open(filename1,'w')\n",
    "    fm=open(filename2,'w')\n",
    "    fr=open(filename3,'w')\n",
    "    fl.write('#Formula'+'\\t'+'MPID'+'\\t'+'Frequency'+'\\n')\n",
    "    fm.write('#Formula'+'\\t'+'MPID'+'\\t'+'Frequency'+'\\n')\n",
    "    fr.write('#Formula'+'\\t'+'MPID'+'\\t'+'Frequency'+'\\n')\n",
    "    \n",
    "    for i in LeftNums:\n",
    "        MatIndex=CompIDs.index(i)\n",
    "        MatName=Compositions[MatIndex][1]\n",
    "        Frequency=LeftCount[i]\n",
    "        fl.write(MatName+'\\t'+str(i)+'\\t'+str(Frequency)+'\\n')\n",
    "    for i in MidNums:\n",
    "        MatIndex=CompIDs.index(i)\n",
    "        MatName=Compositions[MatIndex][1]\n",
    "        Frequency=MidCount[i]\n",
    "        fm.write(MatName+'\\t'+str(i)+'\\t'+str(Frequency)+'\\n')\n",
    "    for i in RightNums:\n",
    "        MatIndex=CompIDs.index(i)\n",
    "        MatName=Compositions[MatIndex][1]\n",
    "        Frequency=RightCount[i]\n",
    "        fr.write(MatName+'\\t'+str(i)+'\\t'+str(Frequency)+'\\n')\n",
    "    fl.close()\n",
    "    fm.close()\n",
    "    fr.close()    \n",
    "    return\n",
    "\n",
    "\n",
    "AllData=np.genfromtxt('CNData_DensityEHullNAt_CompENeg_GapCorrCNL0.txt',dtype=None) #This includes the gap correction\n",
    "OpticalData=np.genfromtxt('OpticalProperties.txt',dtype=None)\n",
    "OpticIDs=[]\n",
    "for i in range(0,len(OpticalData)):\n",
    "    OpticIDs.append(OpticalData[i][0])\n",
    "ElectronicIDs=[]\n",
    "for i in range(0,len(AllData)):\n",
    "    ElectronicIDs.append(AllData[i][0])\n",
    "\n",
    "ChoosePhotolayers(Lefts, Middles, Rights, LeftMinGap, LeftMaxGap, PhotoMinGap, PhotoMaxGap, RightMinGap, RightMaxGap, LeftRequireDirect, RequireDirect, RightRequireDirect)\n",
    "\n",
    "for iterloop in range(0,iterations):\n",
    "    print(iterloop)\n",
    "    directory=topDirectory+'Iteration'+str(iterloop)+'/' #where output files will be written\n",
    "    if not os.path.exists(directory): #make directory\n",
    "        os.makedirs(directory)\n",
    "    AssembleFiles=[] #list of material file to assemble structures.  Order: LMR\n",
    "    for layerPos in AllLayers: #loop over all layer positions\n",
    "        if layerPos in Layers: #Layer to perform SVM\n",
    "            trainingFileG=directory+'SVMTraining'+'Iteration'+str(iterloop)+'Good'+layerPos+'.txt' #good training data\n",
    "            trainingFileB=directory+'SVMTraining'+'Iteration'+str(iterloop)+'Bad'+layerPos+'.txt' #bad training data\n",
    "            fG=open(trainingFileG,'w')\n",
    "            fB=open(trainingFileB,'w')\n",
    "            if layerPos=='Left':\n",
    "                for j in LeftTrainingInitialGood:\n",
    "                    fG.write(str(j)+'\\n')\n",
    "                for j in LeftTrainingInitialBad:\n",
    "                    fB.write(str(j)+'\\n')\n",
    "            elif layerPos=='Middle':\n",
    "                for j in MiddleTrainingInitialGood:\n",
    "                    fG.write(str(j)+'\\n')\n",
    "                for j in MiddleTrainingInitialBad:\n",
    "                    fB.write(str(j)+'\\n')\n",
    "            elif layerPos=='Right':\n",
    "                for j in RightTrainingInitialGood:\n",
    "                    fG.write(str(j)+'\\n')\n",
    "                for j in RightTrainingInitialBad:\n",
    "                    fB.write(str(j)+'\\n')\n",
    "            fB.close()\n",
    "            fG.close()\n",
    "            AssembleFiles.append(SVMMaterial(iterloop,layerPos))\n",
    "        else: #layer not to perform SVM\n",
    "            copyfile(topDirectory+'Heterostructure'+layerPos+'.txt',directory+'Heterostructure'+layerPos+'.txt')\n",
    "            AssembleFiles.append(directory+'Heterostructure'+layerPos+'.txt')\n",
    "\n",
    "    #Now combine approved materials into heterostructure\n",
    "    structuresFile=ConstructHeterostructures(AssembleFiles)\n",
    "\n",
    "    #Count each layer\n",
    "    CountStructures(structuresFile)\n",
    "\n",
    "    #find most common layers for SVM\n",
    "    for qq in AllLayers:\n",
    "        if qq in Layers: #Layers to SVM\n",
    "            Frequencies=np.atleast_1d(np.array(np.genfromtxt(directory+'11'+qq+'Frequencies.txt',dtype=None)))\n",
    "            Frequencies = sorted(Frequencies, key=lambda Frequencies_entry: Frequencies_entry[2], reverse=True)\n",
    "            totalMaterials=len(Frequencies)\n",
    "            numAdd=int(math.ceil(SVMAppendFrac*totalMaterials))\n",
    "            for rr in range(0,numAdd):\n",
    "                if qq=='Left' and 'Left' in Layers:\n",
    "                    LeftTrainingInitialGood.append(Frequencies[rr][1])\n",
    "                elif qq=='Right' and 'Right' in Layers:\n",
    "                    RightTrainingInitialGood.append(Frequencies[rr][1])\n",
    "                elif qq=='Middle' and 'Middle' in Layers:\n",
    "                    MiddleTrainingInitialGood.append(Frequencies[rr][1])\n",
    "    \n",
    "    LeftTrainingInitialGood=list(set(LeftTrainingInitialGood))\n",
    "    MiddleTrainingInitialGood=list(set(MiddleTrainingInitialGood))\n",
    "    RightTrainingInitialGood=list(set(RightTrainingInitialGood))\n",
    "    \n",
    "    LeftTrainingInitialBad=LeftTrainingInitialBad+RightTrainingInitialGood\n",
    "    RightTrainingInitialBad=RightTrainingInitialBad+LeftTrainingInitialGood\n",
    "    \n",
    "    #for each side make sure no material is both good and bad\n",
    "    LeftConflicts=list(set(LeftTrainingInitialGood) & set(LeftTrainingInitialBad))\n",
    "    if LeftConflicts:\n",
    "        for LCons in LeftConflicts:\n",
    "            LeftTrainingInitialGood.remove(LCons)\n",
    "            LeftTrainingInitialBad.remove(LCons)\n",
    "    RightConflicts=list(set(RightTrainingInitialGood) & set(RightTrainingInitialBad))\n",
    "    if RightConflicts:\n",
    "        for RCons in RightConflicts:\n",
    "            RightTrainingInitialGood.remove(RCons)\n",
    "            RightTrainingInitialBad.remove(RCons)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is the function used to rank structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Resistance(ETLe,Ae,Ah,HTLh):\n",
    "    return((ETLe+0.5*Ae+0.5*Ah+HTLh)**(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final cell below sorts by the figure of merit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-1529a774dc41>:3: UserWarning: genfromtxt: Empty input file: \"Heterostructures_CdSe-1NoSVM/Iteration0/AllPossibleHeterostructures_AllFilters_LinCorr.txt\"\n",
      "  Structures=np.genfromtxt(file,dtype=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "iteration=0\n",
    "file=topDirectory+'Iteration'+str(iteration)+'/AllPossibleHeterostructures_AllFilters_LinCorr.txt'\n",
    "Structures=np.genfromtxt(file,dtype=None)\n",
    "#print(Structures)\n",
    "\n",
    "OpticalData=np.genfromtxt('OpticalProperties.txt',dtype=None)\n",
    "OpticIDs=[]\n",
    "for i in range(0,len(OpticalData)):\n",
    "    OpticIDs.append(OpticalData[i][0])\n",
    "#print(OpticIDs)\n",
    "\n",
    "OutFile=topDirectory+'Iteration'+str(iteration)+'/Structs.txt'\n",
    "f=open(OutFile,'w')\n",
    "#f.write('#LMPID'+'\\t'+'CMPID'+'\\t'+'RMPID'+'\\t'+'LName'+'\\t'+'CName'+'\\t'+'RName'+'\\t'+'LGap'+'\\t'+'CGap'+'\\t'+'RGap'+'\\t'+'EDiff1'+'\\t'+'EDiff2'+'\\t'+'EDiff3'+'\\t'+'EDiff4'+'\\t'+'CVBM'+'\\t'+'Cost'+'\\t'+'ETLeMass'+'\\t'+'ActiveeMass'+'\\t'+'ActivehMass'+'\\t'+'HTLhMass'+'\\t'+'Resistive'+'\\n')\n",
    "\n",
    "for i in range(0,len(Structures)):\n",
    "    Mat0=Structures[i][0] #left, ETL\n",
    "    Mat1=Structures[i][1] # active layer\n",
    "    Mat2=Structures[i][2] #right, HTL\n",
    "    \n",
    "    Mat0Loc=OpticIDs.index(Mat0)\n",
    "    Mat1Loc=OpticIDs.index(Mat1)\n",
    "    Mat2Loc=OpticIDs.index(Mat2)\n",
    "\n",
    "    ETLeMass=OpticalData[Mat0Loc][2]\n",
    "    ActiveeMass=OpticalData[Mat1Loc][2]\n",
    "    ActivehMass=OpticalData[Mat1Loc][3]\n",
    "    HTLhMass=OpticalData[Mat2Loc][3]\n",
    "    \n",
    "    #Write data to new file\n",
    "    for item in Structures[i]:\n",
    "        f.write(str(item)+'\\t')\n",
    "    for item in [ETLeMass,ActiveeMass,ActivehMass,HTLhMass]:\n",
    "        f.write(str(item)+'\\t')\n",
    "    f.write(str(Resistance(ETLeMass,ActiveeMass,ActivehMass,HTLhMass))+'\\n')\n",
    "f.close()\n",
    "\n",
    "#Sort file\n",
    "os.system('sort -k20nr '+ OutFile +'> '+topDirectory+'Iteration'+str(iteration)+'/SortedStructures.txt')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
